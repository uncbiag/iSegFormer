{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isegm.model.modeling.swin_transformer import *\n",
    "from isegm.model.modeling.swin_unet import *\n",
    "from isegm.model.is_swinformer_model import SwinformerModel\n",
    "from isegm.model.modeling.transformer_helper.cross_entropy_loss import CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Swin-base:\n",
    "IMG_SIZE = 384\n",
    "DROP_PATH_RATE = 0.2\n",
    "EMBED_DIM = 128\n",
    "DEPTHS = [2, 2, 18, 2]\n",
    "NUM_HEADS = [4, 8, 16, 32]\n",
    "WINDOW_SIZE = 12\n",
    "\n",
    "swin_base_backbone_params = dict(\n",
    "    pretrain_img_size=IMG_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    depths=DEPTHS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    window_size=WINDOW_SIZE\n",
    ")\n",
    "\n",
    "swin_base_backbone = SwinTransformer(**swin_base_backbone_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 19:54:54,137 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias, layers.0.blocks.1.attn_mask, layers.1.blocks.1.attn_mask, layers.2.blocks.1.attn_mask, layers.2.blocks.3.attn_mask, layers.2.blocks.5.attn_mask, layers.2.blocks.7.attn_mask, layers.2.blocks.9.attn_mask, layers.2.blocks.11.attn_mask, layers.2.blocks.13.attn_mask, layers.2.blocks.15.attn_mask, layers.2.blocks.17.attn_mask\n",
      "\n",
      "missing keys in source state_dict: norm0.weight, norm0.bias, norm1.weight, norm1.bias, norm2.weight, norm2.bias, norm3.weight, norm3.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([8, 128, 80, 120]), torch.Size([8, 256, 40, 60]), torch.Size([8, 512, 20, 30]), torch.Size([8, 1024, 10, 15])]\n",
      "torch.Size([8, 1, 80, 120])\n"
     ]
    }
   ],
   "source": [
    "from isegm.model.modeling.transformer_helper.cross_entropy_loss import CrossEntropyLoss\n",
    "import os\n",
    "weight_folder = '/playpen-raid/qinliu/projects/iSegFormer/weights/'\n",
    "swin_base_weight = os.path.join(\n",
    "    weight_folder, 'swin_base_patch4_window12_384_22k.pth')\n",
    "swin_large_weight = os.path.join(\n",
    "    weight_folder, 'swin_base_patch4_window12_384_22k.pth')\n",
    "\n",
    "swin_base_backbone.init_weights(swin_base_weight)\n",
    "\n",
    "in_t = torch.randn((8, 3, 320, 480))\n",
    "coord_t = torch.randn((8, 3, 320, 480))\n",
    "out_t = swin_base_backbone(in_t, coord_t)\n",
    "print([out_t[i].shape for i in range(len(out_t))])\n",
    "\n",
    "swin_base_head_params = dict(\n",
    "    in_channels=[128, 256, 512, 1024],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=1,\n",
    "    loss_decode=CrossEntropyLoss(),\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "swin_base_head = SwinTransfomerSegHead(**swin_base_head_params)\n",
    "out = swin_base_head(out_t)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24]), torch.Size([8, 768, 12, 12])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "B, H, W, Ch = 8, 384, 384, 3\n",
    "in_t = torch.randn((B, Ch, H, W))\n",
    "\n",
    "backbone_params = dict(\n",
    "    pretrain_img_size=W,\n",
    "    ape=False,\n",
    "    patch_size=4,\n",
    "    embed_dim=128,\n",
    "    window_size=12\n",
    ")\n",
    "\n",
    "backbone = SwinTransformer(**backbone_params)\n",
    "out_t = backbone(in_t)\n",
    "print([out_t[i].shape for i in range(len(out_t))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 80, 120])\n"
     ]
    }
   ],
   "source": [
    "from isegm.model.modeling.transformer_helper.cross_entropy_loss import CrossEntropyLoss\n",
    "decode_head_params = dict(\n",
    "    in_channels=[96, 192, 384, 768],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=1,\n",
    "    loss_decode=CrossEntropyLoss(),\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "head = SwinTransfomerSegHead(**decode_head_params)\n",
    "out = head(out_t)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.1;num_classes:2\n",
      "---final upsample expand_first---\n",
      "torch.Size([8, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "B, W, L, Ch = 8, 224, 224, 3\n",
    "in_t = torch.randn((B, Ch, W, L))\n",
    "swin_unet = SwinTransformerSys(img_size=224, num_classes=2)\n",
    "out_t = swin_unet(in_t)\n",
    "print(out_t.shape)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89c9d8a920cc6bbfac98998034c8a15ed2e75dae1678af787f4c4e38e5be518"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
