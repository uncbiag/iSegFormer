{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from isegm.model.modeling.segformer import MixVisionTransformer, SegformerHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretrained_B2_C = '/playpen-raid/qinliu/projects/ritm_interactive_segmentation/weights/pretrained/mit_b2_converted.pth'\n",
    "\n",
    "backbone_params = dict(\n",
    "    in_channels=6,\n",
    "    embed_dims=64,\n",
    "    num_stages=4,\n",
    "    num_layers=[3, 4, 6, 3],\n",
    "    num_heads=[1, 2, 5, 8],\n",
    "    patch_sizes=[7, 3, 3, 3],\n",
    "    strides=[2, 2, 2, 2],\n",
    "    sr_ratios=[8, 4, 2, 1],\n",
    "    out_indices=(0, 1, 2, 3),\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    pretrained=Pretrained_B2_C\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/playpen-raid/qinliu/projects/iSegFormer/isegm/model/modeling/segformer.py:314: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n"
     ]
    }
   ],
   "source": [
    "backbone = MixVisionTransformer(**backbone_params)\n",
    "# backbone.init_weights()\n",
    "state_dict = torch.load(Pretrained_B2_C)\n",
    "# print(state_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove keys\n",
    "# state_dict.pop('layers.0.0.projection.weight')\n",
    "ori_proj_weight = state_dict['layers.0.0.projection.weight']\n",
    "state_dict['layers.0.0.projection.weight'] = torch.cat([ori_proj_weight, ori_proj_weight], dim=1)\n",
    "\n",
    "\n",
    "backbone.load_state_dict(state_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.load_state_dict(state_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(Pretrained_B2_C)\n",
    "#print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isegm.model.modeling.transformer_helper.cross_entropy_loss import CrossEntropyLoss\n",
    "\n",
    "decode_head_params = dict(\n",
    "    in_channels=[64, 128, 320, 512],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=1,\n",
    "    loss_decode=CrossEntropyLoss(),\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "head = SegformerHead(**decode_head_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = (1, 3, 320, 480)\n",
    "input_t = torch.randn(in_shape)\n",
    "\n",
    "additional_shape = (1, 3, 320, 480)\n",
    "additional_t = torch.randn(additional_shape)\n",
    "\n",
    "input_t = torch.cat([input_t, additional_t], dim=1)\n",
    "\n",
    "temp = backbone(input_t)\n",
    "out_t = head(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 64, 160, 240]), torch.Size([1, 128, 80, 120]), torch.Size([1, 320, 40, 60]), torch.Size([1, 512, 20, 30])] torch.Size([1, 1, 160, 240])\n"
     ]
    }
   ],
   "source": [
    "print([temp[i].shape for i in range(len(temp))], out_t.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ef4093ab78b75315b5578de234fc5791126666d11dbc7e5176d4b19b865843"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
