# iSegFormer: Interactive Video/Volume Segmentation using Vision Transformers

## Updates
[03/11/2023] Add code for cycle consistency learning in branch [cycle-learning](https://github.com/uncbiag/iSegFormer/tree/cycle-learning).

## Introduction
This codebase is for interactive video/volume segmentation using cutting-edge vision transformers. It is still under active development. 
To reproduce results of our published papers, please refer to the following branches.

## Branches
> \[[cycle-learning](https://github.com/uncbiag/iSegFormer/tree/cycle-learning)\] Exploring Cycle Consistency Learning in Interactive Volume Segmentation 

> \[[v1.0_miccai22](https://github.com/uncbiag/iSegFormer/tree/v1.0_miccai22)\] iSegFormer: Interactive Image Segmentation via Transformers with Application to 3D Knee MR Images (MICCAI'22)

## License
The code is released under the MIT License. It is a short, permissive software license. Basically, you can do whatever you want as long as you include the original copyright and license notice in any copy of the software/source. 

## Citation
```bibtex
@inproceedings{liu2022isegformer,
  title={iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images},
  author={Liu, Qin and Xu, Zhenlin and Jiao, Yining and Niethammer, Marc},
  booktitle={MICCAI 2022, Proceedings, Part V},
  pages={464--474},
  year={2022},
  organization={Springer}
}
```
